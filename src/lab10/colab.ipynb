{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4dba2153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dba2153",
        "outputId": "0ba6018e-de05-47df-816f-40b85577b5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(!) Make sure this dir is project directory:  /\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "_BASE_DIR = Path().resolve().parent.parent\n",
        "print(\"(!) Make sure this dir is project directory: \", _BASE_DIR)\n",
        "sys.path.append(str(_BASE_DIR))\n",
        "\n",
        "# from utils.settings import get_in_out_dirs\n",
        "\n",
        "# === Настройка директорий под Колаб ===\n",
        "def get_in_out_dirs(base_name: str):\n",
        "    base_dir = Path.cwd()\n",
        "    input_dir = base_dir / \"data\" / \"input\" / base_name\n",
        "    output_dir = base_dir / \"data\" / \"output\" / base_name\n",
        "    input_dir.mkdir(parents=True, exist_ok=True)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    return input_dir, output_dir\n",
        "\n",
        "_LAB_NAME = \"lab10\"\n",
        "\n",
        "INPUT_DIR, OUTPUT_DIR = get_in_out_dirs(base_name=_LAB_NAME)\n",
        "\n",
        "DATA_DIR = INPUT_DIR / \"data\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TRAIN_DIR = DATA_DIR / \"train\"\n",
        "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TEST_DIR = DATA_DIR / \"test\"\n",
        "TEST_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uh5phwvJJS3",
        "outputId": "0b4941fe-74a7-4324-9291-57d73db216fe"
      },
      "id": "0uh5phwvJJS3",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input  output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e9ea596",
      "metadata": {
        "id": "5e9ea596"
      },
      "source": [
        "# Лаб. 10\n",
        "\n",
        "## Задание 1.  (из  тем  10.1–10.2):\n",
        "\n",
        "Обучите рекуррентную нейронную сеть распознаванию тональности отзывов на тестовых данных открытого набора данных imdb.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "c124067c",
      "metadata": {
        "id": "c124067c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9ec0d071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ec0d071",
        "outputId": "15d3cdf1-c4c5-4df2-dc0c-bf4b93a19eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (25000, 256), Test shape: (25000, 256)\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Загружаем данные\n",
        "# -----------------------------\n",
        "NUM_WORDS = 10000  # используем топ-N слов\n",
        "MAX_LEN = 256      # максимальная длина отзыва\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "# Дополняем последовательности до одинаковой длины\n",
        "train_x = pad_sequences(train_x, maxlen=MAX_LEN, padding='post')\n",
        "test_x = pad_sequences(test_x, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "print(f\"Train shape: {train_x.shape}, Test shape: {test_x.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOEknO9QN_Lw",
        "outputId": "54d234d6-161b-48ae-cd1e-147a6d40cd63"
      },
      "id": "AOEknO9QN_Lw",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "95948528",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "95948528",
        "outputId": "edce5f88-3234-43c3-d779-c3795ed43c2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Строим модель LSTM\n",
        "# -----------------------------\n",
        "embedding_dim = 128\n",
        "lstm_units = 128\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=NUM_WORDS, output_dim=embedding_dim),\n",
        "    # LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2),\n",
        "    LSTM(lstm_units), # без dropout, так быстрее на GPU\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "1241d055",
      "metadata": {
        "id": "1241d055"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = OUTPUT_DIR / \"model\"\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_MODEL_PATH = MODEL_DIR / \"imdb_lstm_model.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c2538503",
      "metadata": {
        "id": "c2538503"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "59b24ac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59b24ac2",
        "outputId": "abe64d94-3ca0-4fa4-c309-a563fc2db86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель не найдена, тренируем...\n",
            "Epoch 1/15\n",
            "\u001b[1m155/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6386 - loss: 0.5705\n",
            "Epoch 1: val_loss improved from inf to 0.53913, saving model to /content/data/output/lab10/model/imdb_lstm_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6390 - loss: 0.5709 - val_accuracy: 0.8110 - val_loss: 0.5391\n",
            "Epoch 2/15\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7930 - loss: 0.4983\n",
            "Epoch 2: val_loss did not improve from 0.53913\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7919 - loss: 0.4993 - val_accuracy: 0.5398 - val_loss: 0.6695\n",
            "Epoch 3/15\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6298 - loss: 0.5958\n",
            "Epoch 3: val_loss improved from 0.53913 to 0.46245, saving model to /content/data/output/lab10/model/imdb_lstm_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6303 - loss: 0.5954 - val_accuracy: 0.8180 - val_loss: 0.4625\n",
            "Epoch 4/15\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8632 - loss: 0.3550\n",
            "Epoch 4: val_loss improved from 0.46245 to 0.36295, saving model to /content/data/output/lab10/model/imdb_lstm_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8634 - loss: 0.3547 - val_accuracy: 0.8510 - val_loss: 0.3630\n",
            "Epoch 5/15\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9164 - loss: 0.2420\n",
            "Epoch 5: val_loss improved from 0.36295 to 0.33933, saving model to /content/data/output/lab10/model/imdb_lstm_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9164 - loss: 0.2418 - val_accuracy: 0.8730 - val_loss: 0.3393\n",
            "Epoch 6/15\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9135 - loss: 0.2906\n",
            "Epoch 6: val_loss did not improve from 0.33933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9136 - loss: 0.2903 - val_accuracy: 0.8706 - val_loss: 0.3555\n",
            "Epoch 7/15\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9611 - loss: 0.1413\n",
            "Epoch 7: val_loss did not improve from 0.33933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9611 - loss: 0.1413 - val_accuracy: 0.8702 - val_loss: 0.3763\n",
            "Epoch 8/15\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9738 - loss: 0.1067\n",
            "Epoch 8: val_loss did not improve from 0.33933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9738 - loss: 0.1068 - val_accuracy: 0.8690 - val_loss: 0.3988\n",
            "Модель сохранена в /content/data/output/lab10/model/imdb_lstm_model.h5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# -----------------------------\n",
        "# Обучение или загрузка\n",
        "# -----------------------------\n",
        "\n",
        "force_train = True\n",
        "\n",
        "if not force_train and os.path.exists(OUT_MODEL_PATH):\n",
        "    print(\"Модель найдена, загружаем вместо тренировки...\")\n",
        "    model = load_model(OUT_MODEL_PATH)\n",
        "\n",
        "else:\n",
        "    print(\"Модель не найдена, тренируем...\")\n",
        "\n",
        "    # защита от перетренировки\n",
        "    callbacks = [\n",
        "      EarlyStopping(\n",
        "          monitor=\"val_loss\",      # следим за валидацией\n",
        "          patience=3,              # стоп если N эпохи подряд ухудшение\n",
        "          restore_best_weights=True\n",
        "      ),\n",
        "      ModelCheckpoint(\n",
        "          filepath=OUT_MODEL_PATH,\n",
        "          monitor=\"val_loss\",\n",
        "          save_best_only=True,\n",
        "          verbose=2\n",
        "      )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_x, train_y,\n",
        "        epochs=15,\n",
        "        batch_size=128,\n",
        "        validation_split=0.2,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    print(f\"Модель сохранена в {OUT_MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "7d7d4b6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7d4b6e",
        "outputId": "6db68a88-8d10-4176-f376-43f0e1561bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3525\n",
            "Test loss: 0.3527, Test accuracy: 0.8634\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Оценка модели на тесте\n",
        "# -----------------------------\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a888dd18",
      "metadata": {
        "id": "a888dd18"
      },
      "source": [
        "## Задание 2.  (из  тем  10.1–10.2):\n",
        "\n",
        "С использованием предварительно обученной нейронной сети определите тональность своего отзыва.\n",
        "\n",
        "Прилагаю файл reviews retrieving - скрипт, позволяющий восстанавливать тексты отзывов с Intenet Movie DataBase.\n",
        "\n",
        "В качестве входных данных нужно предоставить текст своего отзыва (можно написать прямо в окне \"Ответ в виде текста\").\n",
        "\n",
        "В качестве результатов, пожалуйста, сдайте обученную рекуррентную нейронную сеть и результат распознавания ею Вашего отзыва."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        num_words: ограничиваем словарь топ-словами (как при обучении IMDB)\n",
        "        max_len: максимальная длина последовательности\n",
        "        \"\"\"\n",
        "        self.num_words = NUM_WORDS\n",
        "        self.max_len = MAX_LEN\n",
        "        self.word_to_id = imdb.get_word_index()\n",
        "        self.word_to_id = {k: (v + 3) for k, v in self.word_to_id.items() if v < self.num_words}\n",
        "        self.word_to_id[\"<PAD>\"] = 0\n",
        "        self.word_to_id[\"<START>\"] = 1\n",
        "        self.word_to_id[\"<UNK>\"] = 2\n",
        "        self.word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        \"\"\"Удаляем пунктуацию, переводим в нижний регистр\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "        return text\n",
        "\n",
        "    def _text_to_sequence(self, text):\n",
        "        \"\"\"Конвертируем текст в список индексов\"\"\"\n",
        "        cleaned = self._clean_text(text)\n",
        "        words = cleaned.split()\n",
        "        sequence = [1]  # <START>\n",
        "        sequence += [self.word_to_id.get(word, 2) for word in words] # 2 = <UNK>\n",
        "        return sequence\n",
        "\n",
        "    def _pad_sequence(self, sequence):\n",
        "        \"\"\"Дополняем последовательность до max_len\"\"\"\n",
        "        return pad_sequences([sequence], maxlen=self.max_len, padding='post')\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        \"\"\"Полная конвертация текста в готовую последовательность для модели\"\"\"\n",
        "        seq = self._text_to_sequence(text)\n",
        "        print(\"seq: \",seq)\n",
        "        print(\"count of <UNK>: \", seq.count(2))\n",
        "        padded = self._pad_sequence(seq)\n",
        "        return padded\n"
      ],
      "metadata": {
        "id": "lfyRh0bAQuSy"
      },
      "id": "lfyRh0bAQuSy",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewTonalityPredictor:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.text_preprocessor = TextPreprocessor()\n",
        "\n",
        "  def predict(self, review: str):\n",
        "    seq = self.text_preprocessor.preprocess(review)\n",
        "    pred = self.model.predict(seq)[0][0]\n",
        "    sep_str = \"\\n\" + \"=\"*50\n",
        "    print(f\"{sep_str} Отзыв: {review[:50]}... {sep_str}\")\n",
        "    print(f\"Тональность вашего отзыва: {'Положительная' if pred>=0.5 else 'Отрицательная'} ({pred:.4f})\\n\")"
      ],
      "metadata": {
        "id": "arPNs306RUus"
      },
      "id": "arPNs306RUus",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "1c8cd1b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c8cd1b8",
        "outputId": "8834c434-cca3-4f43-945a-2b9e8bc8d900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq:  [1, 52, 21, 2]\n",
            "count of <UNK>:  1\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "================================================== Отзыв: Good but idk... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Положительная (0.7862)\n",
            "\n",
            "seq:  [1, 608, 94, 608]\n",
            "count of <UNK>:  0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "================================================== Отзыв: OK its ok... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Отрицательная (0.0318)\n",
            "\n",
            "seq:  [1, 78, 94, 78]\n",
            "count of <UNK>:  0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "================================================== Отзыв: Bad its bad... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Отрицательная (0.0415)\n",
            "\n",
            "seq:  [1, 14, 20, 16, 480, 4, 114, 16, 1728, 5, 4, 105, 71, 867]\n",
            "count of <UNK>:  0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "================================================== Отзыв: This movie was amazing! The plot was engaging and ... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Положительная (0.8287)\n",
            "\n",
            "seq:  [1, 13, 1800, 14, 22, 4, 65, 16, 357, 5, 4, 116, 16, 394]\n",
            "count of <UNK>:  0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "================================================== Отзыв: I hated this film. The story was boring, and the a... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Отрицательная (0.0284)\n",
            "\n",
            "seq:  [1, 4, 627, 16, 307, 21, 4, 65, 16, 6, 227, 727]\n",
            "count of <UNK>:  0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "================================================== Отзыв: The cinematography was beautiful, but the story wa... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Отрицательная (0.4230)\n",
            "\n",
            "seq:  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "count of <UNK>:  9\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            "================================================== Отзыв: Фильм понравился, сюжет интересный, актеры отлично... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Отрицательная (0.3986)\n",
            "\n",
            "seq:  [1, 179, 441, 290, 149, 1453, 86, 58, 18, 4, 114, 333, 58, 8, 2, 49, 7, 4, 2455, 414, 4235, 34, 49, 7, 4, 2, 857, 23, 133, 6459, 135, 25, 242, 28, 8, 30, 120, 4, 559, 7, 3248, 5, 35, 7495, 752, 3042, 8, 1144, 49, 7, 4, 3159, 42, 4, 2, 43, 40, 7018, 49, 7, 68, 5568, 4692, 94, 221, 8, 854, 15, 4, 91, 423, 733, 6, 2, 16, 348, 34, 294, 19, 2, 2, 857, 812, 129, 205, 7830, 44, 15, 2, 2356, 47, 6, 227, 7, 6, 8298, 2, 155, 170, 23, 44, 41]\n",
            "count of <UNK>:  8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            "================================================== Отзыв: Quite entertaining\n",
            "Worth watching twice, first tim... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Положительная (0.7590)\n",
            "\n",
            "seq:  [1, 447, 4, 321, 204, 19, 1378, 2, 38, 16, 267, 930, 8, 14, 811, 964, 437, 7, 58, 138, 127, 259, 181, 8, 106, 4, 4636, 2, 65, 4, 109, 5, 4, 284, 2265, 90, 9, 6, 964, 2, 262, 103, 149, 1378, 2, 2, 5, 2620, 2, 4, 78, 493, 11, 4, 86, 811, 1848, 2, 127, 24, 28, 4, 323, 671, 42, 116, 1959, 8, 30, 4, 485, 5, 4840, 19, 4, 616, 196, 1153, 2, 7631, 5, 2, 4047, 17, 27, 64, 2827, 29, 272, 647, 5, 1297, 17, 6, 3029, 9276, 50, 9, 57, 147, 114, 15, 5115, 25, 342, 672, 11, 5, 71, 2, 5366, 437, 129, 58, 23, 14, 31]\n",
            "count of <UNK>:  10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "================================================== Отзыв: Loved the excellent original with Chris Pratt, so ... \n",
            "==================================================\n",
            "Тональность вашего отзыва: Отрицательная (0.0213)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Распознать мой отзыв\n",
        "# -----------------------------\n",
        "\n",
        "good_review = \"This movie was amazing! The plot was engaging and the characters were believable.\"\n",
        "\n",
        "predictor = ReviewTonalityPredictor(model=model)\n",
        "\n",
        "reviews = [\n",
        "    \"Good but idk\",\n",
        "\n",
        "    \"OK its ok\",\n",
        "\n",
        "    \"Bad its bad\",\n",
        "\n",
        "    # Английский хороший\n",
        "    \"This movie was amazing! The plot was engaging and the characters were believable.\",\n",
        "\n",
        "    # Английский плохой\n",
        "    \"I hated this film. The story was boring, and the acting was terrible.\",\n",
        "\n",
        "    # Английский смешанный\n",
        "    \"The cinematography was beautiful, but the story was a bit predictable.\",\n",
        "\n",
        "    # Русский\n",
        "    \"Фильм понравился, сюжет интересный, актеры отлично справились с ролями.\",\n",
        "\n",
        "    # Длинный английский хороший\n",
        "    \"\"\"Quite entertaining\n",
        "Worth watching twice, first time for the plot, second time to absorb some of the sharp dialogue.\n",
        "\n",
        "Judging by some of the 1/10 reviews on here I'd say you probably have to be over the age of 16 and an IQ above 80 to appreciate some of the irony, or the reviewrs just like releasing some of their angst online. It's interesting to note that the most liked review, a 1/10, was given by someone with 87% 1/10 reviews! Form your own conclusions about that!\n",
        "\n",
        "Brianna Roy has a bit of a Reese Witherspoon thing going on about her.\"\"\",\n",
        "\n",
        "    # Длинный английский плохой\n",
        "    \"\"\"Loved the excellent original with Chris Pratt, so was looking forward to this season. Total waste of time. Why does anyone want to watch the greedy traitor's story? The character and the actor portraying him is a total weeny! Especially after watching Chris Pratt creatively and effectively terminate the bad guys in the first season. Taylor Kitsch does not have the star power or acting skills to be the lead. And what's with the annoying long hair, scruffy beard and pucker lips as his only expression? He looks ridiculous and unbelievable as a Navy seal.\n",
        "\n",
        "There is no real plot that grabs you. 3 episodes in and we're snoring. Don't waste your time on this one.\n",
        "  \"\"\",\n",
        "]\n",
        "\n",
        "predictor = ReviewTonalityPredictor(model=model)\n",
        "\n",
        "for r in reviews:\n",
        "    predictor.predict(r)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1kQl2KEUMGq"
      },
      "id": "x1kQl2KEUMGq",
      "execution_count": 53,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "neural_networks",
      "language": "python",
      "name": "neural_networks"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}